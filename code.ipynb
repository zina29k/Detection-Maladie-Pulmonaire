{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6a791e4-b762-4a6b-a2b5-510ca1c6bd1f",
   "metadata": {},
   "source": [
    "# Détection automatique de maladies pulmonaires à partir de radiographies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7a5c85-875e-4492-9d03-86594cd57a23",
   "metadata": {},
   "source": [
    "### Pré-traitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6eb941a6-1d4a-4f63-935d-8806f637a74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ddce9e0-14f9-4c8d-a3ca-bcc80ea6417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildSampleFromPath(path1, path2, path3, path4):\n",
    "    normal_list = []\n",
    "    covid_list = []\n",
    "    pneumonia_list = []\n",
    "\n",
    "    normal_files = [f for f in os.listdir(path1) if f.lower().endswith(('.png', '.jpg', '.jpeg','.webp'))]\n",
    "    for image_name in normal_files:\n",
    "        chemin = os.path.join(path1, image_name)\n",
    "        normal_list.append((chemin, \"Normal\"))\n",
    "\n",
    "    covid_files = [f for f in os.listdir(path2) if f.lower().endswith(('.png', '.jpg', '.jpeg','.webp'))]\n",
    "    for image_name in covid_files:\n",
    "        chemin = os.path.join(path2, image_name)\n",
    "        covid_list.append((chemin, \"COVID\"))\n",
    "\n",
    "    pneumonia_files = [f for f in os.listdir(path3) if f.lower().endswith(('.png', '.jpg', '.jpeg','.webp'))]\n",
    "    for image_name in pneumonia_files:\n",
    "        chemin = os.path.join(path3, image_name)\n",
    "        pneumonia_list.append((chemin, \"Pneumonia\"))\n",
    "\n",
    "    lung_opacity_files = [f for f in os.listdir(path4) if f.lower().endswith(('.png', '.jpg', '.jpeg','.webp'))]\n",
    "    for image_name in lung_opacity_files:\n",
    "        chemin = os.path.join(path4, image_name)\n",
    "        pneumonia_list.append((chemin, \"Pneumonia\"))\n",
    "\n",
    "    return normal_list, covid_list, pneumonia_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73e7b863-2eb5-4470-8ca0-af82afd4066f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images normales: 10192\n",
      "Nombre d'images COVID: 3616\n",
      "Nombre d'images pneumonies: 7357\n"
     ]
    }
   ],
   "source": [
    "base_path = Path(\"archive/COVID-19_Radiography_Dataset\")\n",
    "\n",
    "path_normal = base_path/\"Normal/images\"\n",
    "path_covid = base_path/\"COVID/images\"    \n",
    "path_pneumonia = base_path/\"Viral Pneumonia/images\"\n",
    "path_lung_opacity = base_path/\"Lung_Opacity/images\"\n",
    "\n",
    "img_normals, img_covids, img_pneumonias = buildSampleFromPath(\n",
    "    path_normal, path_covid, path_pneumonia, path_lung_opacity\n",
    ")\n",
    "\n",
    "print(f\"Nombre d'images normales: {len(img_normals)}\")\n",
    "print(f\"Nombre d'images COVID: {len(img_covids)}\")\n",
    "print(f\"Nombre d'images pneumonies: {len(img_pneumonias)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea6d5056-aa0b-4919-95dd-21e78e294119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d’images : 21165\n"
     ]
    }
   ],
   "source": [
    "all_images = img_normals + img_covids + img_pneumonias\n",
    "print(f\"Total d’images : {len(all_images)}\")\n",
    "\n",
    "random.shuffle(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9cc58b-5122-42c9-a1ca-2ffd1c2ad3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train : 14814\n",
      "Val : 3176\n",
      "Test : 3175\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = train_test_split(all_images, test_size=0.15, stratify=[label for _, label in all_images])\n",
    "train, validation = train_test_split(train_set, test_size=0.1765, stratify=[label for _, label in train_set])\n",
    "\n",
    "print(f\"Train : {len(train)}\")\n",
    "print(f\"Val : {len(validation)}\")\n",
    "print(f\"Test : {len(test_set)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6525439-ca41-4b08-952c-038f23e5fdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CovidDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.label_map = {\"Normal\": 0, \"COVID\": 1, \"Pneumonia\": 2}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.label_map[label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4473f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = ResNet18_Weights.DEFAULT\n",
    "preprocess = weights.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c07a4615-c885-427e-acdd-6962b1989a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CovidDataset(train, transform=preprocess)\n",
    "val_dataset = CovidDataset(validation, transform=preprocess)\n",
    "test_dataset = CovidDataset(test_set, transform=preprocess)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f82bd82e-665a-453a-bf06-6b0064fdf800",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Labels sous forme numérique\n",
    "all_labels = [label for _, label in all_images]\n",
    "label_map = {\"Normal\": 0, \"COVID\": 1, \"Pneumonia\": 2}\n",
    "numerical_labels = [label_map[l] for l in all_labels]\n",
    "\n",
    "# Convertir la liste des classes en array\n",
    "classes_array = np.array([0, 1, 2])\n",
    "\n",
    "# Calcul des poids\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=classes_array, y=numerical_labels)\n",
    "\n",
    "# Transformation en tenseur PyTorch\n",
    "weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Appliquer à la loss\n",
    "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "\n",
    "\n",
    "model = models.resnet18(weights=weights)\n",
    "model.fc = nn.Linear(model.fc.in_features, 3)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823cdd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Définition de l'optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Fonction d'entraînement\n",
    "def train(model, dataloader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    print(f'Train Epoch {epoch} | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.2f}%')\n",
    "\n",
    "# Fonction d'évaluation\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    acc = 100. * correct / total\n",
    "    print(f'Validation Accuracy: {acc:.2f}%')\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e0dad658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 1 | Loss: 0.4218 | Acc: 83.79%\n",
      "Validation Accuracy: 83.75%\n",
      "Train Epoch 2 | Loss: 0.2735 | Acc: 89.50%\n",
      "Validation Accuracy: 70.21%\n",
      "Train Epoch 3 | Loss: 0.2309 | Acc: 90.85%\n",
      "Validation Accuracy: 86.15%\n",
      "Train Epoch 4 | Loss: 0.1934 | Acc: 92.43%\n",
      "Validation Accuracy: 89.17%\n",
      "Train Epoch 5 | Loss: 0.1699 | Acc: 93.41%\n",
      "Validation Accuracy: 88.66%\n",
      "Train Epoch 6 | Loss: 0.1416 | Acc: 94.31%\n",
      "Validation Accuracy: 92.41%\n",
      "Train Epoch 7 | Loss: 0.1314 | Acc: 94.79%\n",
      "Validation Accuracy: 91.50%\n",
      "Train Epoch 8 | Loss: 0.1132 | Acc: 95.46%\n",
      "Validation Accuracy: 90.24%\n",
      "Train Epoch 9 | Loss: 0.0794 | Acc: 96.72%\n",
      "Validation Accuracy: 91.85%\n",
      "Train Epoch 10 | Loss: 0.0751 | Acc: 96.96%\n",
      "Validation Accuracy: 90.68%\n",
      "Train Epoch 11 | Loss: 0.0689 | Acc: 97.41%\n",
      "Validation Accuracy: 88.04%\n",
      "Train Epoch 12 | Loss: 0.0604 | Acc: 97.73%\n",
      "Validation Accuracy: 91.25%\n",
      "Train Epoch 13 | Loss: 0.0490 | Acc: 98.11%\n",
      "Validation Accuracy: 89.48%\n",
      "Train Epoch 14 | Loss: 0.0425 | Acc: 98.30%\n",
      "Validation Accuracy: 87.50%\n",
      "Train Epoch 15 | Loss: 0.0392 | Acc: 98.53%\n",
      "Validation Accuracy: 89.89%\n",
      "Train Epoch 16 | Loss: 0.0386 | Acc: 98.43%\n",
      "Validation Accuracy: 91.59%\n",
      "Train Epoch 17 | Loss: 0.0260 | Acc: 98.95%\n",
      "Validation Accuracy: 91.28%\n",
      "Train Epoch 18 | Loss: 0.0440 | Acc: 98.48%\n",
      "Validation Accuracy: 90.90%\n",
      "Train Epoch 19 | Loss: 0.0176 | Acc: 99.36%\n",
      "Validation Accuracy: 92.00%\n",
      "Train Epoch 20 | Loss: 0.0374 | Acc: 98.68%\n",
      "Validation Accuracy: 90.65%\n"
     ]
    }
   ],
   "source": [
    "# Boucle d'entraînement\n",
    "num_epochs = 20\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(model, train_loader, criterion, optimizer, epoch)\n",
    "    val_acc = evaluate(model, val_loader)\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
